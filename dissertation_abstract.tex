\documentclass[10pt]{article}

\usepackage[english]{babel}
\usepackage{fouriernc}
\usepackage[T1]{fontenc}
\usepackage[paperwidth=130mm, paperheight=126mm, top=0mm, bottom=0mm, left=0mm, right=0.3mm]{geometry}

\begin{document}

\setlength{\parindent}{3mm}
\small

\noindent Multi-label classification is an important topic in machine learning that arises naturally from many real world applications. For example, in document classification, a research article can be categorized as ``science'', ``drug discovery'' and ``genomics'' at the same time. The goal of multi-label classification is to reliably predict multiple outputs (labels) for a given input. As multiple interdependent labels can be ``on'' and ``off'' simultaneously, the central problem in multi-label classification is how to best exploit the correlation between labels to make accurate predictions. Compared to the previous flat multi-label classification approaches which treat multiple labels as a flat vector, structured output learning relies on an output graph connecting multiple labels to model the correlation between labels in a comprehensive manner. The main question studied in this thesis is how to tackle multi-label classification through structured output learning. Within this scope we discuss several subproblems.

This thesis starts with an extensive review on the topic of classification learning including both single-label and multi-label classification. The first problem we address is how to solve the multi-label classification problem when the output graph is observed \textit{apriori}. We discuss several well-established structured output learning algorithms and study the network response prediction problem within the context of social network analysis. As the current structured output learning algorithms rely on the output graph to exploit dependency between labels, the second problem we address is how to use structured output learning when the output graph is not known. Specifically, we examine the potential of learning on a set of random output graphs when the ``real'' one is hidden. This problem is relevant as in most multi-label classification problems there does not exist any output graph that reveals the dependency between labels. The third problem we address is how to analyze the proposed learning algorithms in a theoretical manner. Specially, we want to explain the intuition behind the proposed models and to study the generalization error.

The main contributions of this thesis are several new learning algorithms that widen the applicability of structured output learning. For the problem with observed structure, the proposed algorithm ``{\sc spin}'' is able to predict an optimal directed acyclic graph from an observed underlying network that best responses to an input. For general multi-label classification problems without known output graph, we proposed several learning algorithms that combine many structured output learners built on random output graphs. In addition, we develop a joint learning and inference framework which is based on Max-Margin learning over a random sample of spanning trees. The theoretic analysis also guarantees the generalization error of the proposed methods.

\end{document}