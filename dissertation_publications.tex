

% Errata list, if you have errors in the publications.
%\errata

%
% icml 2014
\addpublication[conference]{Hongyu Su, Aristides Gionis, Juho Rousu}{Structured Prediction of Network Response}{Proceedings of the $31^{th}$ International Conference on Machine Learning (ICML 2014)}{Beijing, China, 2014. JMLR W{\&}CP volume 32:442-450}{June}{2014}{Copyright 2014 by the authors}{su14a}

\addcontribution{

\citepub{su14a} presents a novel formalism of the network response prediction problem, and proposes a structured output prediction algorithm for the problem.
The proposed algorithm \spin\ captures the contextual information and improves the state-of-the-art models in terms of the prediction performance.

The definition of the problem and the initial modeling idea were developed jointly by the authors.
The author made major contribution to designing the learning framework and the optimization algorithm.
The author implemented the whole learning system including \sdp\ and the \greedy\ inference algorithms.
The author designed and performed the experiments and analyzed the results.
The author worked jointly in the designing and writing the research article.

}
%\adderrata{This is wrong}
\addpublicationpdf{publications/su14a.pdf}



%
% prib2010
\addpublication[conference]{Hongyu Su, Markus Heinonen, Juho Rousu}{Multilabel Classification of Drug-like Molecules via Max-margin Conditional Random Fields}{Proceedings of the $5^{th}$ International Conference on Pattern Recognition in Bioinformatics (PRIB 2010)}{Nijmegen, The Netherlands, 2010. Springer LNBI volume 6282:265-273}{September}{2010}{Copyright 2014 by the authors}{su10}

\addcontribution{

\citepub{su10} presents a structured output prediction model for multilabel molecular activity classification problem.
The new model incorporates the correlation of the output variables into the learning process and surpasses the previous single-label classification approach in terms of the prediction performance.

The original modeling idea was jointly proposed.
The author implemented the learning system that applying the structured output learning algorithm for the task.
The author designed and performed the experiments and analyzed the results.
The author participated in designing and writing the research articles.

}
%\adderrata{This is wrong}
\addpublicationpdf{publications/su10.pdf}


%
% prib 2011
\addpublication[conference]{Hongyu Su, Juho Rousu}{Multi-task Drug Bioactivity Classification with Graph Labeling Ensembles}{Proceedings of the $6^{th}$ International Conference on Pattern Recognition in Bioinformatics (PRIB 2011)}{Delft, The Netherlands, 2011. Springer LNBI volume 7035:157-167}{November}{2011}{Copyright 2014 by the authors}{su11}

\addcontribution{

\citepub{su11} extends \citepub{su10} by learning a majority voting ensemble of a set of structured output classifiers built from random output graphs.

The idea of the ensemble learning strategy was jointly developed. 
The author made major contribution to the design of the algorithm.
The author implemented the algorithm, designed and performed the experiments, and analyzed the results.
The author participated in designing and writing the research articles.

}
%\adderrata{This is wrong}
\addpublicationpdf{publications/su11.pdf}

%
% mlj 2014
%Volume, issue, pages, and other detailed information
\addpublication{Hongyu Su, Juho Rousu}{Multilabel Classification through Random Graph Ensembles}{Machine Learning}{DOI:10.1007/s10994-014-5465-9, published online 26 pages}{September}{2014}{Copyright 2014 by the authors}{su14b}

\addcontribution{

\citepub{su14b} extends \citepub{su11} by introducing two aggregation framework (\amm\ and \mam) which perform the inference before or after combining the multiple structure output learners.
The theoretical study in \citepub{su14b} explains the performance of the proposed \mam\ model.
The performance of the proposed models are examined on a set of heterogeneous multilabel prediction problems.

The modeling idea was developed jointly by authors.
The author designed and implemented the learning frameworks and the optimization algorithms.
The author developed the theorem explaining the performance of \mam.
The author designed and conducted the experiments and analyzed the results.
The author worked jointly in the designing and writing the research article.

}
%\adderrata{This is wrong}
\addpublicationpdf{publications/su14b.pdf}




%
% nips 2014
\addpublication[conference]{Mario Marchand, Hongyu Su, Emilie Morvant, Juho Rousu, John Shawe-Taylor}{Multilabel Structured Output Learning with Random Spanning Trees of Max-Margin Markov Networks}{Proceedings of the $28^{th}$ Advances in Neural Information Processing Systems (NIPS 2014)}{accepted 9 pages}{December}{2014}{Copyright 2014 by the authors}{su14c}

\addcontribution{

\citepub{su14c} is a major step forward of \citepub{su14b} by introducing the joint learning and inference framework and developing rigorous learning theory to backup the algorithm.

The idea was initialized jointly by the authors.
The author worked jointly on the development of the theories and the proofs.
The author made major contribution to the learning framework and optimization algorithms.
The author implemented the whole learning system.
The author designed and performed the experiments and analyzed the results.
The author participated in designing and writing the research articles.
}
%\adderrata{This is wrong}
\addpublicationpdf{publications/su14c.pdf}
\addpublicationpdf{publications/su14c_supplementary.pdf}
